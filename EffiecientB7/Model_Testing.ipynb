{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
      "Predicted class index: 9\n",
      "Predicted class name: Painted Stork\n",
      "Ashy crowned sparrow lark: 0.0000\n",
      "Asian Openbill: 0.0031\n",
      "Black-headed ibis: 0.0000\n",
      "Crow: 0.0000\n",
      "Eurasian Coot: 0.0000\n",
      "Indian Roller: 0.0000\n",
      "Large-billed Crow: 0.0000\n",
      "Little Cormorant: 0.0000\n",
      "Paddyfield pipit: 0.0000\n",
      "Painted Stork: 0.9969\n",
      "Red-wattled lapwing: 0.0000\n",
      "Spot-billed Pelician: 0.0000\n",
      "White-breasted Waterhen: 0.0000\n",
      "Yellow wattled lapwing: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"Model_V3_7525.h5\")\n",
    "\n",
    "# Define the directory where your classes (folder names) are located\n",
    "# class_names = os.listdir(train_dir)  # Get class names from train_dir\n",
    "class_names = ['Ashy crowned sparrow lark', 'Asian Openbill', 'Black-headed ibis', 'Crow', 'Eurasian Coot', 'Indian Roller', 'Large-billed Crow', 'Little Cormorant', 'Paddyfield pipit', 'Painted Stork', 'Red-wattled lapwing', 'Spot-billed Pelician', 'White-breasted Waterhen', 'Yellow wattled lapwing']\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input\n",
    "    # img_array /= 255.0  # Rescale the image (assuming the model was trained with rescaled images)\n",
    "    return img_array\n",
    "\n",
    "# Test with an input image\n",
    "input_image_path = \"E:\\CAPSTONE\\Bird_Species_Classification\\Models\\FINAL MODELS\\EffiecientB7\\SDP_Project\\Images for Testing\\images (5).jpeg\"  # Replace with your image path\n",
    "img_array = preprocess_image(input_image_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "predicted_class_name = class_names[predicted_class_index[0]]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Predicted class index: {predicted_class_index[0]}\")\n",
    "print(f\"Predicted class name: {predicted_class_name}\")\n",
    "\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE FOR TESTING WITH USER SELECTED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Predicted class index: 9\n",
      "Predicted class name: Painted Stork\n",
      "Ashy crowned sparrow lark: 0.0000\n",
      "Asian Openbill: 0.0031\n",
      "Black-headed ibis: 0.0000\n",
      "Crow: 0.0000\n",
      "Eurasian Coot: 0.0000\n",
      "Indian Roller: 0.0000\n",
      "Large-billed Crow: 0.0000\n",
      "Little Cormorant: 0.0000\n",
      "Paddyfield pipit: 0.0000\n",
      "Painted Stork: 0.9969\n",
      "Red-wattled lapwing: 0.0000\n",
      "Spot-billed Pelician: 0.0000\n",
      "White-breasted Waterhen: 0.0000\n",
      "Yellow wattled lapwing: 0.0000\n",
      "\n",
      "After User Selection Adjustment:\n",
      "Ashy crowned sparrow lark: 0.0000\n",
      "Asian Openbill: 0.0007\n",
      "Black-headed ibis: 0.0000\n",
      "Crow: 0.0000\n",
      "Eurasian Coot: 0.0000\n",
      "Indian Roller: 0.0000\n",
      "Large-billed Crow: 0.0000\n",
      "Little Cormorant: 0.0000\n",
      "Paddyfield pipit: 0.0000\n",
      "Painted Stork: 0.9993\n",
      "Red-wattled lapwing: 0.0000\n",
      "Spot-billed Pelician: 0.0000\n",
      "White-breasted Waterhen: 0.0000\n",
      "Yellow wattled lapwing: 0.0000\n",
      "Final Predicted Class after Adjustment: Painted Stork\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"Model_V3_7525.h5\")\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['Ashy crowned sparrow lark', 'Asian Openbill', 'Black-headed ibis', 'Crow', 'Eurasian Coot', 'Indian Roller', 'Large-billed Crow', 'Little Cormorant', 'Paddyfield pipit', 'Painted Stork', 'Red-wattled lapwing', 'Spot-billed Pelician', 'White-breasted Waterhen', 'Yellow wattled lapwing']\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input\n",
    "    return img_array\n",
    "\n",
    "# Function to adjust probabilities based on user selection\n",
    "def adjust_probabilities(predictions, selected_class_index, boost_factor=4.2):\n",
    "    predictions = predictions[0]  # Extract single prediction row\n",
    "    predictions[selected_class_index] *= boost_factor  # Increase selected class probability\n",
    "    predictions /= np.sum(predictions)  # Normalize to keep sum = 1\n",
    "    return predictions\n",
    "\n",
    "# Test with an input image\n",
    "input_image_path = \"E:\\CAPSTONE\\Bird_Species_Classification\\Models\\FINAL MODELS\\EffiecientB7\\SDP_Project\\Images for Testing\\images (5).jpeg\"\n",
    "img_array = preprocess_image(input_image_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "# Print initial results\n",
    "print(f\"Predicted class index: {predicted_class_index}\")\n",
    "print(f\"Predicted class name: {predicted_class_name}\")\n",
    "\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "# Assume the user selects a class from suggested images (simulated input)\n",
    "user_selected_class = \"Painted Stork\"  # Change this to simulate different selections\n",
    "selected_index = class_names.index(user_selected_class)\n",
    "\n",
    "# Adjust probabilities based on user selection\n",
    "adjusted_predictions = adjust_probabilities(predictions, selected_index)\n",
    "\n",
    "# Get the final predicted class after adjustment\n",
    "final_predicted_class_index = np.argmax(adjusted_predictions)\n",
    "final_predicted_class_name = class_names[final_predicted_class_index]\n",
    "\n",
    "print(\"\\nAfter User Selection Adjustment:\")\n",
    "for i, prob in enumerate(adjusted_predictions):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "print(f\"Final Predicted Class after Adjustment: {final_predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code For multiple User Selected Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "Predicted class index: 3\n",
      "Predicted class name: Crow\n",
      "Ashy crowned sparrow lark: 0.0000\n",
      "Asian Openbill: 0.0002\n",
      "Black-headed ibis: 0.0000\n",
      "Crow: 0.8413\n",
      "Eurasian Coot: 0.0004\n",
      "Indian Roller: 0.0000\n",
      "Large-billed Crow: 0.1571\n",
      "Little Cormorant: 0.0005\n",
      "Paddyfield pipit: 0.0002\n",
      "Painted Stork: 0.0000\n",
      "Red-wattled lapwing: 0.0000\n",
      "Spot-billed Pelician: 0.0000\n",
      "White-breasted Waterhen: 0.0004\n",
      "Yellow wattled lapwing: 0.0000\n",
      "\n",
      "After User Selection Adjustment:\n",
      "Ashy crowned sparrow lark: 0.0000\n",
      "Asian Openbill: 0.0001\n",
      "Black-headed ibis: 0.0000\n",
      "Crow: 0.2981\n",
      "Eurasian Coot: 0.0001\n",
      "Indian Roller: 0.0000\n",
      "Large-billed Crow: 0.7013\n",
      "Little Cormorant: 0.0002\n",
      "Paddyfield pipit: 0.0001\n",
      "Painted Stork: 0.0000\n",
      "Red-wattled lapwing: 0.0000\n",
      "Spot-billed Pelician: 0.0000\n",
      "White-breasted Waterhen: 0.0001\n",
      "Yellow wattled lapwing: 0.0000\n",
      "Final Predicted Class after Adjustment: Large-billed Crow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"Model_V3_7525.h5\")\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['Ashy crowned sparrow lark', 'Asian Openbill', 'Black-headed ibis', 'Crow', 'Eurasian Coot', 'Indian Roller', 'Large-billed Crow', 'Little Cormorant', 'Paddyfield pipit', 'Painted Stork', 'Red-wattled lapwing', 'Spot-billed Pelician', 'White-breasted Waterhen', 'Yellow wattled lapwing']\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input\n",
    "    return img_array\n",
    "\n",
    "# Function to adjust probabilities based on multiple user selections\n",
    "def adjust_probabilities(predictions, selected_classes, base_boost=4.2):\n",
    "    predictions = predictions[0]  # Extract single prediction row\n",
    "    \n",
    "    for selected_class in selected_classes:\n",
    "        selected_index = class_names.index(selected_class)\n",
    "        predictions[selected_index] *= (base_boost * selected_classes[selected_class])  # Boost based on count\n",
    "    \n",
    "    predictions /= np.sum(predictions)  # Normalize to keep sum = 1\n",
    "    return predictions\n",
    "\n",
    "# Test with an input image\n",
    "input_image_path = \"E:\\CAPSTONE\\Bird_Species_Classification\\Models\\FINAL MODELS\\EffiecientB7\\SDP_Project\\Images for Testing\\images.jpeg\"\n",
    "img_array = preprocess_image(input_image_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "# Print initial results\n",
    "print(f\"Predicted class index: {predicted_class_index}\")\n",
    "print(f\"Predicted class name: {predicted_class_name}\")\n",
    "\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "# Assume the user selects multiple classes (simulated input with count)\n",
    "user_selected_classes = {\"Large-billed Crow\": 3}  # Example selection\n",
    "\n",
    "# Adjust probabilities based on user selections\n",
    "adjusted_predictions = adjust_probabilities(predictions, user_selected_classes)\n",
    "\n",
    "# Get the final predicted class after adjustment\n",
    "final_predicted_class_index = np.argmax(adjusted_predictions)\n",
    "final_predicted_class_name = class_names[final_predicted_class_index]\n",
    "\n",
    "print(\"\\nAfter User Selection Adjustment:\")\n",
    "for i, prob in enumerate(adjusted_predictions):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "print(f\"Final Predicted Class after Adjustment: {final_predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE With Option for user to Select None Of the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Predicted class index: 6\n",
      "Predicted class name: Large-billed Crow\n",
      "Ashy crowned sparrow lark: 0.0072\n",
      "Asian Openbill: 0.0009\n",
      "Black-headed ibis: 0.0007\n",
      "Crow: 0.1087\n",
      "Eurasian Coot: 0.0000\n",
      "Indian Roller: 0.0102\n",
      "Large-billed Crow: 0.4394\n",
      "Little Cormorant: 0.0019\n",
      "Paddyfield pipit: 0.0393\n",
      "Painted Stork: 0.0000\n",
      "Red-wattled lapwing: 0.0109\n",
      "Spot-billed Pelician: 0.0001\n",
      "White-breasted Waterhen: 0.0013\n",
      "Yellow wattled lapwing: 0.3795\n",
      "\n",
      "User selected 'None of the images'. No boosting applied.\n",
      "\n",
      "After User Selection Adjustment:\n",
      "Ashy crowned sparrow lark: 0.0072\n",
      "Asian Openbill: 0.0009\n",
      "Black-headed ibis: 0.0007\n",
      "Crow: 0.1087\n",
      "Eurasian Coot: 0.0000\n",
      "Indian Roller: 0.0102\n",
      "Large-billed Crow: 0.4394\n",
      "Little Cormorant: 0.0019\n",
      "Paddyfield pipit: 0.0393\n",
      "Painted Stork: 0.0000\n",
      "Red-wattled lapwing: 0.0109\n",
      "Spot-billed Pelician: 0.0001\n",
      "White-breasted Waterhen: 0.0013\n",
      "Yellow wattled lapwing: 0.3795\n",
      "Final Decision: Unknown Bird (Not in Dataset)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"Model_V3_7525.h5\")\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['Ashy crowned sparrow lark', 'Asian Openbill', 'Black-headed ibis', 'Crow', 'Eurasian Coot', \n",
    "               'Indian Roller', 'Large-billed Crow', 'Little Cormorant', 'Paddyfield pipit', 'Painted Stork', \n",
    "               'Red-wattled lapwing', 'Spot-billed Pelician', 'White-breasted Waterhen', 'Yellow wattled lapwing']\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match model input\n",
    "    return img_array\n",
    "\n",
    "# Function to adjust probabilities based on multiple user selections\n",
    "def adjust_probabilities(predictions, selected_classes, base_boost=4.2):\n",
    "    predictions = predictions[0]  # Extract single prediction row\n",
    "\n",
    "    if \"None\" in selected_classes:  \n",
    "        print(\"\\nUser selected 'None of the images'. No boosting applied.\")\n",
    "        return predictions  # Return original probabilities\n",
    "\n",
    "    for selected_class in selected_classes:\n",
    "        selected_index = class_names.index(selected_class)\n",
    "        predictions[selected_index] *= (base_boost * selected_classes[selected_class])  # Boost based on count\n",
    "\n",
    "    predictions /= np.sum(predictions)  # Normalize to keep sum = 1\n",
    "    return predictions\n",
    "\n",
    "# Test with an input image\n",
    "input_image_path = \"E:\\CAPSTONE\\Bird_Species_Classification\\Models\\FINAL MODELS\\EffiecientB7\\SDP_Project\\Images for Testing\\images (4).jpeg\"\n",
    "img_array = preprocess_image(input_image_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "# Print initial results\n",
    "print(f\"Predicted class index: {predicted_class_index}\")\n",
    "print(f\"Predicted class name: {predicted_class_name}\")\n",
    "\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "# Assume the user selects multiple classes (simulated input with count)\n",
    "user_selected_classes = {\"None\": 1}  # Example: User selects \"None of the images\"\n",
    "\n",
    "# Adjust probabilities based on user selections\n",
    "adjusted_predictions = adjust_probabilities(predictions, user_selected_classes)\n",
    "\n",
    "# Get the final predicted class after adjustment\n",
    "final_predicted_class_index = np.argmax(adjusted_predictions)\n",
    "final_predicted_class_name = class_names[final_predicted_class_index]\n",
    "\n",
    "print(\"\\nAfter User Selection Adjustment:\")\n",
    "for i, prob in enumerate(adjusted_predictions):\n",
    "    print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "if \"None\" in user_selected_classes:\n",
    "    print(\"Final Decision: Unknown Bird (Not in Dataset)\")\n",
    "else:\n",
    "    print(f\"Final Predicted Class after Adjustment: {final_predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as t\n",
    "print(t.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.38-py3-none-any.whl (896 kB)\n",
      "     -------------------------------------- 896.3/896.3 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.8-cp39-cp39-win_amd64.whl (441 kB)\n",
      "     -------------------------------------- 441.4/441.4 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (1.24.4)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "     ---------------------------------------- 38.8/38.8 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (9.2.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (0.19.1+cu124)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (2.4.1+cu124)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.28.1)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.5.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (0.11.2)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.0-cp39-cp39-win_amd64.whl (90 kB)\n",
      "     ---------------------------------------- 90.7/90.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp) (21.4.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "     ---------------------------------------- 51.8/51.8 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp39-cp39-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.6/45.6 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.9.14)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Installing collected packages: py-cpuinfo, propcache, opencv-python, multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, ultralytics-thop, aiohttp, ultralytics\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.8 aiosignal-1.3.1 async-timeout-5.0.1 frozenlist-1.5.0 multidict-6.1.0 opencv-python-4.10.0.84 propcache-0.2.0 py-cpuinfo-9.0.0 ultralytics-8.3.38 ultralytics-thop-2.0.12 yarl-1.18.0\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22708\\283014451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# Run the app\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0muvicorn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"0.0.0.0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\uvicorn\\main.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mMultiprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# pragma: full coverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\uvicorn\\server.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\asyncio\\runners.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         raise RuntimeError(\n\u001b[0m\u001b[0;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from ultralytics import YOLO\n",
    "import aiohttp\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import json\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Load YOLOv8 pretrained model for bird detection\n",
    "yolo_model = YOLO(\"yolov8x.pt\")  # Pretrained model (COCO dataset)\n",
    "bird_class_index = 14  # Bird class ID in COCO dataset\n",
    "\n",
    "# Load the custom classification model for bird species\n",
    "classification_model = tf.keras.models.load_model(\"Model_V3_7525.h5\")\n",
    "\n",
    "class_names = [\n",
    "    'Ashy crowned sparrow lark', 'Asian Openbill', 'Black-headed ibis', 'Crow',\n",
    "    'Eurasian Coot', 'Indian Roller', 'Large-billed Crow', 'Little Cormorant',\n",
    "    'Paddyfield pipit', 'Painted Stork', 'Red-wattled lapwing', 'Spot-billed Pelican',\n",
    "    'White-breasted Waterhen', 'Yellow wattled lapwing'\n",
    "]\n",
    "\n",
    "# Define request body schema\n",
    "class ImageURL(BaseModel):\n",
    "    image_url: str\n",
    "\n",
    "# Helper function to fetch image from a URL\n",
    "async def fetch_image_from_url(image_url: str):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(image_url) as response:\n",
    "            if response.status != 200:\n",
    "                raise HTTPException(status_code=404, detail=\"Image not found\")\n",
    "            image_data = await response.read()\n",
    "            img = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "            return np.array(img)\n",
    "\n",
    "# Preprocess the image for classification\n",
    "def preprocess_image_for_classification(cropped_img):\n",
    "    cropped_img = cropped_img.resize((224, 224))  # Resize to model input size\n",
    "    img_array = image.img_to_array(cropped_img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions\n",
    "    img_array /= 255.0  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Draw text with a background on the image\n",
    "def draw_text_with_background(draw, text, position, font_size=24):\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    text_bbox = draw.textbbox(position, text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    padding = 8\n",
    "    background_bbox = [\n",
    "        position[0] - padding,\n",
    "        position[1] - padding,\n",
    "        position[0] + text_width + padding,\n",
    "        position[1] + text_height + padding\n",
    "    ]\n",
    "    # Semi-transparent black background\n",
    "    draw.rectangle(background_bbox, fill=(0, 0, 0, 180))\n",
    "    draw.text(position, text, fill='white', font=font)\n",
    "\n",
    "# Route to detect birds in an image\n",
    "@app.post(\"/predict/\")\n",
    "async def predict_bird_in_image(data: ImageURL):\n",
    "    # Fetch the image from the provided URL\n",
    "    img = await fetch_image_from_url(data.image_url)\n",
    "\n",
    "    # Perform detection using YOLOv8 model\n",
    "    results = yolo_model.predict(img)\n",
    "    # Extract detected class IDs\n",
    "    detected_classes = results[0].boxes.cls.numpy()\n",
    "\n",
    "    # Check if a bird is detected\n",
    "    bird_count = sum(1 for cls in detected_classes if cls == bird_class_index)\n",
    "    if bird_count > 0:\n",
    "        return {\"isBird\": True, \"birdCount\": bird_count}\n",
    "    else:\n",
    "        return {\"isBird\": False, \"birdCount\": 0}\n",
    "\n",
    "# Route to classify bird species in an image\n",
    "@app.post(\"/classify/\")\n",
    "async def classify_bird_in_image(data: ImageURL):\n",
    "    # Fetch the image from the provided URL\n",
    "    img = await fetch_image_from_url(data.image_url)\n",
    "\n",
    "    # Convert to PIL image for further processing\n",
    "    img_pil = Image.fromarray(img)\n",
    "\n",
    "    # Detect bird presence using YOLOv8\n",
    "    results = yolo_model.predict(img_pil)\n",
    "    detected_boxes = results[0].boxes.xyxy.numpy()  # Extract bounding boxes\n",
    "    detected_classes = results[0].boxes.cls.numpy()\n",
    "\n",
    "    classified_birds = []\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    for box, cls in zip(detected_boxes, detected_classes):\n",
    "        if cls == bird_class_index:  # Check if class is a bird\n",
    "            # Crop the bird region for classification\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cropped_img = img_pil.crop((x1, y1, x2, y2))\n",
    "\n",
    "            # Preprocess and classify\n",
    "            img_array = preprocess_image_for_classification(cropped_img)\n",
    "            predictions = classification_model.predict(img_array, verbose=0)\n",
    "            predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "            predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "            # Save the classification result\n",
    "            classified_birds.append(predicted_class_name)\n",
    "\n",
    "            # Annotate the image\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0), width=3)\n",
    "            draw_text_with_background(\n",
    "                draw, predicted_class_name, (x1, y1 - 30))\n",
    "\n",
    "    # Save the annotated image locally\n",
    "    img_pil.save(\"classified_image.jpg\")\n",
    "\n",
    "    if not classified_birds:\n",
    "        return {\"message\": \"No birds detected\"}\n",
    "\n",
    "    return {\n",
    "        \"classified_birds\": classified_birds,\n",
    "        \"message\": f\"Classified {len(classified_birds)} bird(s). Annotated image saved as 'classified_image.jpg'\"\n",
    "    }\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
